{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "PCrK_9WGm27n"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from unicodedata import normalize \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional,LSTM, Dropout, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical, plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/English to French.csv', mode = 'r', encoding = 'utf-8') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "koiQ2Fk8n02z"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "6JSQwIh_n_aR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split a loaded document into sentences\n",
        "def to_pairs(doc):\n",
        "\tlines = doc.strip().split('\\n')\n",
        "\tpairs = [line.split('\\t') for line in  lines]\n",
        "\treturn pairs"
      ],
      "metadata": {
        "id": "qE_IYzajoB8D"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "JLwrjvHcpIFo",
        "outputId": "cde8c7cc-6675-4995-ddd6-56e520df9a3d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_pairs(lines):\n",
        "\tcleaned = list()\n",
        "\t# prepare regex for char filtering\n",
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "\t# prepare translation table for removing punctuation\n",
        "\ttable = str.maketrans('', '', string.punctuation)\n",
        "\tfor pair in lines:\n",
        "\t\tclean_pair = list()\n",
        "\t\tfor line in pair:\n",
        "\t\t\t# normalize unicode characters\n",
        "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "\t\t\tline = line.decode('UTF-8')\n",
        "            #line = line.decode('unicode-escape')\n",
        "\t\t\t# tokenize on white space\n",
        "\t\t\tline = line.split()\n",
        "\t\t\t# convert to lowercase\n",
        "\t\t\tline = [word.lower() for word in line]\n",
        "\t\t\t# remove punctuation from each token\n",
        "\t\t\tline = [word.translate(table) for word in line]\n",
        "\t\t\t# remove non-printable chars form each token\n",
        "\t\t\tline = [re_print.sub('', w) for w in line]\n",
        "\t\t\t# remove tokens with numbers in them\n",
        "\t\t\tline = [word for word in line if word.isalpha()]\n",
        "\t\t\t# store as string\n",
        "\t\t\tclean_pair.append(' '.join(line))\n",
        "\t\tcleaned.append(clean_pair)\n",
        "\treturn np.array(cleaned)"
      ],
      "metadata": {
        "id": "S-d1YRuZvbSR"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = to_pairs(text)\n",
        "clean_pairs = clean_pairs(pairs)\n",
        "for i in range(100):\n",
        "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fweNKC83W0cp",
        "outputId": "133dae56-f747-4327-cd70-ce441764a6ac"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[go] => [va]\n",
            "[hi] => [salut]\n",
            "[hi] => [salut]\n",
            "[run] => [cours]\n",
            "[run] => [courez]\n",
            "[who] => [qui]\n",
            "[wow] => [ca alors]\n",
            "[fire] => [au feu]\n",
            "[help] => [a laide]\n",
            "[jump] => [saute]\n",
            "[stop] => [ca suffit]\n",
            "[stop] => [stop]\n",
            "[stop] => [arretetoi]\n",
            "[wait] => [attends]\n",
            "[wait] => [attendez]\n",
            "[go on] => [poursuis]\n",
            "[go on] => [continuez]\n",
            "[go on] => [poursuivez]\n",
            "[hello] => [bonjour]\n",
            "[hello] => [salut]\n",
            "[i see] => [je comprends]\n",
            "[i try] => [jessaye]\n",
            "[i won] => [jai gagne]\n",
            "[i won] => [je lai emporte]\n",
            "[i won] => [jai gagne]\n",
            "[oh no] => [oh non]\n",
            "[attack] => [attaque]\n",
            "[attack] => [attaquez]\n",
            "[cheers] => [sante]\n",
            "[cheers] => [a votre sante]\n",
            "[cheers] => [merci]\n",
            "[cheers] => [tchintchin]\n",
            "[get up] => [levetoi]\n",
            "[go now] => [va maintenant]\n",
            "[go now] => [allezy maintenant]\n",
            "[go now] => [vasy maintenant]\n",
            "[got it] => [jai pige]\n",
            "[got it] => [compris]\n",
            "[got it] => [pige]\n",
            "[got it] => [compris]\n",
            "[got it] => [tas capte]\n",
            "[hop in] => [monte]\n",
            "[hop in] => [montez]\n",
            "[hug me] => [serremoi dans tes bras]\n",
            "[hug me] => [serrezmoi dans vos bras]\n",
            "[i fell] => [je suis tombee]\n",
            "[i fell] => [je suis tombe]\n",
            "[i know] => [je sais]\n",
            "[i left] => [je suis parti]\n",
            "[i left] => [je suis partie]\n",
            "[i lost] => [jai perdu]\n",
            "[i paid] => [jai paye]\n",
            "[im] => [jai ans]\n",
            "[im ok] => [je vais bien]\n",
            "[im ok] => [ca va]\n",
            "[listen] => [ecoutez]\n",
            "[no way] => [cest pas possible]\n",
            "[no way] => [impossible]\n",
            "[no way] => [en aucun cas]\n",
            "[no way] => [sans facons]\n",
            "[no way] => [cest hors de question]\n",
            "[no way] => [il nen est pas question]\n",
            "[no way] => [cest exclu]\n",
            "[no way] => [en aucune maniere]\n",
            "[no way] => [hors de question]\n",
            "[really] => [vraiment]\n",
            "[really] => [vrai]\n",
            "[really] => [ah bon]\n",
            "[thanks] => [merci]\n",
            "[we try] => [on essaye]\n",
            "[we won] => [nous avons gagne]\n",
            "[we won] => [nous gagnames]\n",
            "[we won] => [nous lavons emporte]\n",
            "[we won] => [nous lemportames]\n",
            "[ask tom] => [demande a tom]\n",
            "[awesome] => [fantastique]\n",
            "[be calm] => [sois calme]\n",
            "[be calm] => [soyez calme]\n",
            "[be calm] => [soyez calmes]\n",
            "[be cool] => [sois detendu]\n",
            "[be fair] => [sois juste]\n",
            "[be fair] => [soyez juste]\n",
            "[be fair] => [soyez justes]\n",
            "[be fair] => [sois equitable]\n",
            "[be fair] => [soyez equitable]\n",
            "[be fair] => [soyez equitables]\n",
            "[be kind] => [sois gentil]\n",
            "[be nice] => [sois gentil]\n",
            "[be nice] => [sois gentille]\n",
            "[be nice] => [soyez gentil]\n",
            "[be nice] => [soyez gentille]\n",
            "[be nice] => [soyez gentils]\n",
            "[be nice] => [soyez gentilles]\n",
            "[beat it] => [degage]\n",
            "[call me] => [appellemoi]\n",
            "[call me] => [appellezmoi]\n",
            "[call us] => [appellenous]\n",
            "[call us] => [appeleznous]\n",
            "[come in] => [entrez]\n",
            "[come in] => [entre]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = clean_pairs[:15000, :]\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H9I_zsCXly4",
        "outputId": "35cc9cdb-9e7d-491a-c6a3-849f475ce519"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15000"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Data**"
      ],
      "metadata": {
        "id": "pgQqBIKmYf4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(dataset)"
      ],
      "metadata": {
        "id": "mEwjC4q-YQyb"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test =train_test_split(dataset, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "0XnI589qYl00"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train), len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gecKxFbOZNBY",
        "outputId": "d7d76645-9616-471a-b9af-f3a30add6f8d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 3000)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZhghG5GZOQG",
        "outputId": "89f30e51-fd67-4ab0-8058-70e8d74b37a9"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['youre shy', 'tu es timide',\n",
              "       'ccby france attribution tatoebaorg ck sacredceltic'],\n",
              "      dtype='<U339')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Model**"
      ],
      "metadata": {
        "id": "D3LmguMoZbVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer(x):   \n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(x)\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "dtgs9B6dZSV0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max sentence length\n",
        "def max_length(lines):\n",
        "\treturn max(len(line.split()) for line in lines)"
      ],
      "metadata": {
        "id": "fCjQFl4niodj"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode and pad sequences\n",
        "def encode_sequences(tokenizer, length, lines):\n",
        "\tX = tokenizer.texts_to_sequences(lines)\n",
        "\tX = pad_sequences(X, maxlen=length, padding='post')\n",
        "\treturn X"
      ],
      "metadata": {
        "id": "VBX_ww2Cioyt"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encode target sequence\n",
        "def encode_output(sequences, vocab_size):\n",
        "\tylist = list()\n",
        "\tfor sequence in sequences:\n",
        "\t\tencoded = to_categorical(sequence, num_classes=vocab_size)\n",
        "\t\tylist.append(encoded)\n",
        "\ty = np.array(ylist)\n",
        "\ty = y.reshape(sequences.shape[0], sequences.shape[1], vocab_size)\n",
        "\treturn y"
      ],
      "metadata": {
        "id": "JHvuKJediuhE"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare english tokenizer\n",
        "eng_tokenizer = tokenizer(dataset[:, 0])\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "eng_length = max_length(dataset[:, 0])\n",
        "print('English Vocabulary Size: %d' % eng_vocab_size)\n",
        "print('English Max Length: %d' % (eng_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yja7kJWhkaPL",
        "outputId": "c38f6c2b-25c1-49c8-b47b-c3cecb0c2d3a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Vocabulary Size: 2888\n",
            "English Max Length: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare french tokenizer\n",
        "fre_tokenizer = tokenizer(dataset[:, 1])\n",
        "fre_vocab_size = len(fre_tokenizer.word_index) + 1\n",
        "fre_length = max_length(dataset[:, 1])\n",
        "print('French Vocabulary Size: %d' % fre_vocab_size)\n",
        "print('French Max Length: %d' % (fre_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy_FkIImmBzC",
        "outputId": "11244819-6a1d-4533-eb9f-800d6a90b82a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "French Vocabulary Size: 5797\n",
            "French Max Length: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = encode_sequences(fre_tokenizer, fre_length, train[:, 1])\n",
        "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])\n",
        "trainY = encode_output(trainY, eng_vocab_size)"
      ],
      "metadata": {
        "id": "EoT03184mlPz"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testX = encode_sequences(fre_tokenizer, fre_length, test[:, 1])\n",
        "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])\n",
        "testY = encode_output(testY, eng_vocab_size)"
      ],
      "metadata": {
        "id": "OoHbNc4PmlJg"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "\tEmbedding(fre_vocab_size, 256, input_length=fre_length, mask_zero=True),\n",
        "\tLSTM(256),\n",
        "\tRepeatVector(eng_length),\n",
        "\tLSTM(256, return_sequences=True),\n",
        "\tTimeDistributed(Dense(eng_vocab_size, activation='softmax'))\n",
        "])"
      ],
      "metadata": {
        "id": "_ijCnCwsj4Cr"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z80FQYOAm1fB",
        "outputId": "e8c12914-9fa1-4eb6-aee7-01c315a431c3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 11, 256)           1484032   \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 256)               525312    \n",
            "                                                                 \n",
            " repeat_vector_1 (RepeatVect  (None, 5, 256)           0         \n",
            " or)                                                             \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 5, 256)            525312    \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 5, 2888)          742216    \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,276,872\n",
            "Trainable params: 3,276,872\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy')"
      ],
      "metadata": {
        "id": "82AuuMqKkH1Z"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, epochs=30, batch_size=64, validation_data=(testX, testY), verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m-FRqLxlZko",
        "outputId": "9ac3052e-2018-4cb7-8b05-fccde8d5ba73"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "188/188 - 15s - loss: 4.3271 - val_loss: 3.6460 - 15s/epoch - 80ms/step\n",
            "Epoch 2/30\n",
            "188/188 - 2s - loss: 3.4893 - val_loss: 3.5039 - 2s/epoch - 13ms/step\n",
            "Epoch 3/30\n",
            "188/188 - 2s - loss: 3.3134 - val_loss: 3.3760 - 2s/epoch - 11ms/step\n",
            "Epoch 4/30\n",
            "188/188 - 2s - loss: 3.1211 - val_loss: 3.2480 - 2s/epoch - 12ms/step\n",
            "Epoch 5/30\n",
            "188/188 - 3s - loss: 2.9419 - val_loss: 3.1003 - 3s/epoch - 14ms/step\n",
            "Epoch 6/30\n",
            "188/188 - 3s - loss: 2.7562 - val_loss: 2.9743 - 3s/epoch - 14ms/step\n",
            "Epoch 7/30\n",
            "188/188 - 2s - loss: 2.5887 - val_loss: 2.8833 - 2s/epoch - 12ms/step\n",
            "Epoch 8/30\n",
            "188/188 - 3s - loss: 2.4307 - val_loss: 2.7761 - 3s/epoch - 15ms/step\n",
            "Epoch 9/30\n",
            "188/188 - 2s - loss: 2.2708 - val_loss: 2.6790 - 2s/epoch - 13ms/step\n",
            "Epoch 10/30\n",
            "188/188 - 3s - loss: 2.1193 - val_loss: 2.6019 - 3s/epoch - 15ms/step\n",
            "Epoch 11/30\n",
            "188/188 - 2s - loss: 1.9813 - val_loss: 2.5402 - 2s/epoch - 12ms/step\n",
            "Epoch 12/30\n",
            "188/188 - 2s - loss: 1.8517 - val_loss: 2.4716 - 2s/epoch - 11ms/step\n",
            "Epoch 13/30\n",
            "188/188 - 3s - loss: 1.7237 - val_loss: 2.4273 - 3s/epoch - 15ms/step\n",
            "Epoch 14/30\n",
            "188/188 - 2s - loss: 1.6072 - val_loss: 2.3703 - 2s/epoch - 12ms/step\n",
            "Epoch 15/30\n",
            "188/188 - 3s - loss: 1.4910 - val_loss: 2.3305 - 3s/epoch - 17ms/step\n",
            "Epoch 16/30\n",
            "188/188 - 2s - loss: 1.3793 - val_loss: 2.2874 - 2s/epoch - 11ms/step\n",
            "Epoch 17/30\n",
            "188/188 - 2s - loss: 1.2724 - val_loss: 2.2476 - 2s/epoch - 11ms/step\n",
            "Epoch 18/30\n",
            "188/188 - 2s - loss: 1.1719 - val_loss: 2.2379 - 2s/epoch - 11ms/step\n",
            "Epoch 19/30\n",
            "188/188 - 2s - loss: 1.0760 - val_loss: 2.1999 - 2s/epoch - 11ms/step\n",
            "Epoch 20/30\n",
            "188/188 - 3s - loss: 0.9847 - val_loss: 2.1750 - 3s/epoch - 16ms/step\n",
            "Epoch 21/30\n",
            "188/188 - 2s - loss: 0.8983 - val_loss: 2.1660 - 2s/epoch - 12ms/step\n",
            "Epoch 22/30\n",
            "188/188 - 2s - loss: 0.8184 - val_loss: 2.1473 - 2s/epoch - 12ms/step\n",
            "Epoch 23/30\n",
            "188/188 - 2s - loss: 0.7446 - val_loss: 2.1253 - 2s/epoch - 11ms/step\n",
            "Epoch 24/30\n",
            "188/188 - 2s - loss: 0.6795 - val_loss: 2.1257 - 2s/epoch - 11ms/step\n",
            "Epoch 25/30\n",
            "188/188 - 3s - loss: 0.6143 - val_loss: 2.1187 - 3s/epoch - 14ms/step\n",
            "Epoch 26/30\n",
            "188/188 - 2s - loss: 0.5572 - val_loss: 2.1149 - 2s/epoch - 13ms/step\n",
            "Epoch 27/30\n",
            "188/188 - 2s - loss: 0.5054 - val_loss: 2.1078 - 2s/epoch - 11ms/step\n",
            "Epoch 28/30\n",
            "188/188 - 2s - loss: 0.4609 - val_loss: 2.0994 - 2s/epoch - 11ms/step\n",
            "Epoch 29/30\n",
            "188/188 - 2s - loss: 0.4190 - val_loss: 2.1002 - 2s/epoch - 12ms/step\n",
            "Epoch 30/30\n",
            "188/188 - 2s - loss: 0.3833 - val_loss: 2.1110 - 2s/epoch - 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb1965f1760>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}